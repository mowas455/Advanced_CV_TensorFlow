{"metadata":{"accelerator":"GPU","colab":{"name":"C3_W1_Lab_2_Transfer_Learning_CIFAR_10.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n\n# Transfer Learning\nIn this notebook, you will perform transfer learning to train CIFAR-10 dataset on ResNet50 model available in Keras.\n\n","metadata":{"id":"FStp_vbUkRz5"}},{"cell_type":"markdown","source":"## Imports","metadata":{"id":"qpiJj8ym0v0-"}},{"cell_type":"code","source":"import os, re, time, json\nimport PIL.Image, PIL.ImageFont, PIL.ImageDraw\nimport numpy as np\ntry:\n  # %tensorflow_version only exists in Colab.\n  %tensorflow_version 2.x\nexcept Exception:\n  pass\nimport tensorflow as tf\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom matplotlib import pyplot as plt\nimport tensorflow_datasets as tfds\n\nprint(\"Tensorflow version \" + tf.__version__)","metadata":{"id":"AoilhmYe1b5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parameters","metadata":{"id":"HuG_q_1jkaZ6"}},{"cell_type":"markdown","source":"- Define the batch size\n- Define the class (category) names","metadata":{"id":"v4ocPhg6J_xw"}},{"cell_type":"code","source":"BATCH_SIZE = 32 \nclasses = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']","metadata":{"id":"cCpkS9C_H7Tl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define some functions that will help you to create some visualizations. (These will be used later)","metadata":{"id":"O-o96NnyJ_xx"}},{"cell_type":"code","source":"#@title Visualization Utilities[RUN ME]\n#Matplotlib config\nplt.rc('image', cmap='gray')\nplt.rc('grid', linewidth=0)\nplt.rc('xtick', top=False, bottom=False, labelsize='large')\nplt.rc('ytick', left=False, right=False, labelsize='large')\nplt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\nplt.rc('text', color='a8151a')\nplt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\nMATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n# utility to display a row of digits with their predictions\ndef display_images(digits, predictions, labels, title):\n\n  n = 10\n\n  indexes = np.random.choice(len(predictions), size=n)\n  n_digits = digits[indexes]\n  n_predictions = predictions[indexes]\n  n_predictions = n_predictions.reshape((n,))\n  n_labels = labels[indexes]\n \n  fig = plt.figure(figsize=(20, 4))\n  plt.title(title)\n  plt.yticks([])\n  plt.xticks([])\n\n  for i in range(10):\n    ax = fig.add_subplot(1, 10, i+1)\n    class_index = n_predictions[i]\n    \n    plt.xlabel(classes[class_index])\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(n_digits[i])\n\n# utility to display training and validation curves\ndef plot_metrics(metric_name, title, ylim=5):\n  plt.title(title)\n  plt.ylim(0,ylim)\n  plt.plot(history.history[metric_name],color='blue',label=metric_name)\n  plt.plot(history.history['val_' + metric_name],color='green',label='val_' + metric_name)","metadata":{"id":"CfFqJxrzoj5Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading and Preprocessing Data\n[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset has 32 x 32 RGB images belonging to 10 classes. You will load the dataset from Keras.","metadata":{"id":"wPq4Sw5akosT"}},{"cell_type":"code","source":"(training_images, training_labels) , (validation_images, validation_labels) = tf.keras.datasets.cifar10.load_data()","metadata":{"id":"E103YDdQ8NNq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize Dataset\n\nUse the `display_image` to view some of the images and their class labels.","metadata":{"id":"prd944ThNavt"}},{"cell_type":"code","source":"display_images(training_images, training_labels, training_labels, \"Training Data\" )","metadata":{"id":"UiokWTuKo88c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_images(validation_images, validation_labels, validation_labels, \"Training Data\" )","metadata":{"id":"-q35q41KNfxH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess Dataset\nHere, you'll perform normalization on images in training and validation set. \n- You'll use the function [preprocess_input](https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py) from the ResNet50 model in Keras.","metadata":{"id":"ltKfwrCVNuIu"}},{"cell_type":"code","source":"def preprocess_image_input(input_images):\n  input_images = input_images.astype('float32')\n  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n  return output_ims\n","metadata":{"id":"JIxdiJVKArC6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X = preprocess_image_input(training_images)\nvalid_X = preprocess_image_input(validation_images)","metadata":{"id":"QOqjKzgAEU-Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define the Network\nYou will be performing transfer learning on **ResNet50** available in Keras.\n- You'll load pre-trained **imagenet weights** to the model.\n- You'll choose to retain all layers of **ResNet50** along with the final classification layers.","metadata":{"id":"2fooPL9Gkuox"}},{"cell_type":"code","source":"'''\nFeature Extraction is performed by ResNet50 pretrained on imagenet weights. \nInput size is 224 x 224.\n'''\ndef feature_extractor(inputs):\n\n  feature_extractor = tf.keras.applications.resnet.ResNet50(input_shape=(224, 224, 3),\n                                               include_top=False,\n                                               weights='imagenet')(inputs)\n  return feature_extractor\n\n\n'''\nDefines final dense layers and subsequent softmax layer for classification.\n'''\ndef classifier(inputs):\n    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n    x = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"classification\")(x)\n    return x\n\n'''\nSince input image size is (32 x 32), first upsample the image by factor of (7x7) to transform it to (224 x 224)\nConnect the feature extraction and \"classifier\" layers to build the model.\n'''\ndef final_model(inputs):\n\n    resize = tf.keras.layers.UpSampling2D(size=(7,7))(inputs)\n\n    resnet_feature_extractor = feature_extractor(resize)\n    classification_output = classifier(resnet_feature_extractor)\n\n    return classification_output\n\n'''\nDefine the model and compile it. \nUse Stochastic Gradient Descent as the optimizer.\nUse Sparse Categorical CrossEntropy as the loss function.\n''' \n\n\ndef define_compile_model():\n  inputs = tf.keras.layers.Input(shape=(32,32,3))\n  \n  classification_output = final_model(inputs) \n  model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n \n  model.compile(optimizer='SGD', \n                loss='sparse_categorical_crossentropy',\n                metrics = ['accuracy'])\n  \n  return model\n\n\nmodel = define_compile_model()\n\nmodel.summary()","metadata":{"id":"56y8UNFQIVwj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the model","metadata":{"id":"CuhDh8ao8VyB"}},{"cell_type":"code","source":"# this will take around 20 minutes to complete\nEPOCHS = 4\nhistory = model.fit(train_X, training_labels, epochs=EPOCHS, validation_data = (valid_X, validation_labels), batch_size=64)","metadata":{"id":"2K6RNDqtJ_xx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate the Model\n\nCalculate the loss and accuracy metrics using the model's `.evaluate` function.","metadata":{"id":"CYb5sAEmk4ut"}},{"cell_type":"code","source":"loss, accuracy = model.evaluate(valid_X, validation_labels, batch_size=64)","metadata":{"id":"io7Fuu-w3PZi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot Loss and Accuracy Curves\n\nPlot the loss (in blue) and validation loss (in green).","metadata":{"id":"yml-phRfPeOj"}},{"cell_type":"code","source":"plot_metrics(\"loss\", \"Loss\")","metadata":{"id":"b1ZMMJ6T921A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot the training accuracy (blue) as well as the validation accuracy (green).","metadata":{"id":"QbnWIbeJJ_xx"}},{"cell_type":"code","source":"plot_metrics(\"accuracy\", \"Accuracy\")","metadata":{"id":"P0YpFs3J99eO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize predictions\nYou can take a look at the predictions on the validation set.","metadata":{"id":"9jFVovcUUVs1"}},{"cell_type":"code","source":"probabilities = model.predict(valid_X, batch_size=64)\nprobabilities = np.argmax(probabilities, axis = 1)\n\ndisplay_images(validation_images, probabilities, validation_labels, \"Bad predictions indicated in red.\")","metadata":{"id":"NIQAqkMV9adq"},"execution_count":null,"outputs":[]}]}